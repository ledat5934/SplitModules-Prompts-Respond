[
  {
    "id": "2",
    "name": "Toxic comment classification",
    "input_data": "The primary input data is a single text field, `comment_text`, which contains the content of an online comment. A key characteristic of this task is the cross-lingual setting: the training data is entirely in English",
    "output_data": "The output is a single probability value between 0.0 and 1.0. This value represents the likelihood that the given `comment_text` is \"toxic\", where 1.0 indicates a toxic comment and 0.0 indicates a non-toxic comment.",
    "task": "The objective is to build a model that can classify whether an online comment is toxic. Predict the toxicity of the comment in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
      "jigsaw-toxic-comment-train.csv": "These are the primary training files, containing a large number of comments in English, each with a `comment_text` and a `toxic` label (0 or 1).",
      "test.csv": "The test dataset, evaluate the model on this dataset.This file does not contain the `toxic` label.",
      "sample_submission.csv": "An example file showing the required submission format, which includes an `id` column and a `toxic` probability column."
    },
    "link to the dataset": [
      "first_5\\datasets\\toxic_cmt_classify\\jigsaw-toxic-comment-train.csv",
      "first_5\\datasets\\toxic_cmt_classify\\test.csv",
      "first_5\\datasets\\toxic_cmt_classify\\sample_submission.csv"
    ]
  },
  {
    "id": "3",
    "name": "Domain classification",
    "input_data": "The input data for each sample consists of 1 text fields:`Title`: The title of the paper.",
    "output_data": "The output is a probability distribution across numbers of domains.",
    "task": "The objective is to build a model that can classify the domain of a paper based on its title.Predict the domain of the paper in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": "`train.csv`: Contains the training data. Each row represents a paper and includes its `Title` and `Domain`, `train.csv` is the training dataset, `test.csv` is the test dataset, `sample_submission.csv` is the sample submission file",
    "link to the dataset": [
      "first_5\\datasets\\query_domain_classification\\train.csv",
      "first_5\\datasets\\query_domain_classification\\test.csv",
      "first_5\\datasets\\query_domain_classification\\Submission_file01.csv"
    ]
  },
  {
    "id": "4",
    "name": "Predict LLM",
    "input_data": "The input data for each sample consists of two text fields: `Question` (the original prompt or question that was given to a language model) and `Response` (the text output that was generated by one of the language models in response to the `Question`).",
    "output_data": "The output is a probability distribution across 7 possible classes. Each class corresponds to one of the 7 different LLM models that could have generated the `Response`. The final submission requires predicting the probability for each of the 7 models (target_0 to target_6).",
    "task": " For each given pair of `Question` and `Response`, identify which of the 7 LLM models generated the `Response`. This is a multi-class classification task where the output is a set of probabilities for each class, predict the probability for each of the 7 models (target_0 to target_6) in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
		"train.csv": "Contains the training data with three columns: `Question`, `Response`, and `target` (an integer from 0 to 6 indicating the correct model).",
		"test.csv": "Contains the test data with three columns: `id`, `Question`, and `Response`. The goal is to predict the target probabilities for these samples.",
		"sample_submission.csv": "An example submission file showing the required format, which includes an `id` column and 7 probability columns (`target_0` through `target_6`)"
	},
    "link to the dataset": [
      "first_5\\datasets\\predict_the_llm\\train.csv",
      "first_5\\datasets\\predict_the_llm\\test.csv",
      "first_5\\datasets\\predict_the_llm\\sample_submission.csv"
    ]
  },
  {
    "id": "5",
    "name": "Multilabel classification",
    "input_data": "The input data is multimodal, consisting of two parts for each sample: Image Data (A JPEG image file) and Text Data (Optional: A short text caption that summarizes the image).",
    "output_data": "The output is a set of one or more labels for each image. There are 18 possible labels in total, represented by integers ranging from 1 to 19 (with the number 12 missing).",
    "task": "For each given sample, predict all applicable labels. Since a single image can have multiple labels simultaneously, this is a multi-label classification task. The model should be trained on images and can optionally use the text captions as additional input. Predict the labels for all the images in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description":{
		"train.csv": "The training set file. It contains three columns: `ImageID` (the filename of the image), `Labels` (a space-separated string of label numbers for that image), and `Caption` (the text caption)",
		"data/": "A directory containing all the image files in `.jpg` format.",
		"test.csv": "The test set file. It contains `ImageID` and `Caption` for the test samples.",
		"sample_submission.csv": "Example of an submission file, notice that the rows number is not the same as the test.csv"
	},
    "link to the dataset": [
      "E:\\UET\\Lab\\AutoPipelineML\\MultilabelClassify\\COMP5329S1A2Dataset\\data",
      "E:\\UET\\Lab\\AutoPipelineML\\MultilabelClassify\\COMP5329S1A2Dataset\\train.csv"
    ]
  },
  {
    "id": "6",
    "name": "Plant Traits 2024",
    "input_data": "The input data is multimodal, consisting of two main types for each sample: 1) Image Data: A crowd-sourced photograph of a plant (`.jpeg`). 2) Tabular Ancillary Data: A set of geographical and environmental features associated with the image's location. This includes climate data (WORLDCLIM), soil data (SOIL), and multi-temporal satellite data (MODIS, VOD).",
    "output_data": "The output consists of 6 continuous numerical values. Each value is a prediction for one of the 6 vital plant traits , representing properties like leaf area or plant height.",
    "task": "For each sample, predict the values for all 6 plant traits based on the plant image and its associated ancillary data. This is a multi-output regression task that requires a multi-modal model to handle both image and tabular inputs. Predict the values for all 6 plant traits based on the plant image and its associated ancillary data in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
		"train.csv": "Contains the training data. For each `id`, it includes the target values for the 6 plant traits (columns named `X[*]_mean`) and all the ancillary tabular data (columns like `WORLDCLIM_BIO[*]`, `SOIL_[*]`, etc.)",
		"train_images/": "A directory containing the training images, with filenames corresponding to the `id` in `train.csv`",
		"target_name_meta.tsv": "A helper file providing the full names and descriptions for each trait ID.",
		"test.csv": "Contains the ancillary tabular data for the test set. It does not contain the target trait values.",
		"test_images/": "A directory containing the test images.",
		"sample_submission.csv": "An example file showing the required submission format, which includes an `id` column and a prediction column for each of the 6 traits."
	},
    "link to the dataset": [
      "E:\\UET\\Lab\\AutoPipelineML\\PlantTraits\\train.csv",
      "E:\\UET\\Lab\\AutoPipelineML\\PlantTraits\\train_images",
      "E:\\UET\\Lab\\AutoPipelineML\\PlantTraits\\target_name_meta.tsv"
    ]
  },
  {
    "id": "7",
    "name": "Predict Effective Arguement",
    "input_data": "The input data for each sample is a specific argumentative \"discourse element\" from a student's essay. To provide full context, the input consists of three parts:\n- `discourse_text`: The text of the specific discourse element itself.\n- `discourse_type`: The type of the element (e.g., 'Lead', 'Position', 'Claim', 'Evidence', etc.).\n- `essay_text`: The full text of the essay from which the discourse element was extracted.",
    "output_data": "The output is a probability distribution across 3 possible quality ratings for the discourse element. The three classes are: \"Ineffective\", \"Adequate\", and \"Effective\".",
    "task": "For each given argumentative discourse element, predict the quality rating of the discourse element. Predict the quality rating of the discourse element in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": "- `train.csv`: Contains the training data. Each row represents an annotated discourse element and includes its `discourse_id`, the `essay_id` it belongs to, the `discourse_text`, the `discourse_type`, and the target label `discourse_effectiveness`.\n- `test.csv`: Contains the test data with the same fields as `train.csv`, except for the target label.\n- `train/`: A directory containing the full text of each training essay, stored in `.txt` files. The filename of each `.txt` file corresponds to an `essay_id` in `train.csv`.\n- `test/`: A directory containing the full text of each test essay.\n- `sample_submission.csv`: An example file showing the required submission format, which includes `discourse_id` and a probability column for each of the 3 classes.",
    "link to the dataset":[
      "first_5\\datasets\\predict_effective_arguments\\train.csv",
      "first_5\\datasets\\predict_effective_arguments\\test.csv",
      "first_5\\datasets\\predict_effective_arguments\\sample_submission.csv",
      "first_5\\datasets\\predict_effective_arguments\\train",
      "first_5\\datasets\\predict_effective_arguments\\test"
    ]
  }
]