[
  {
    "id": "2",
    "name": "Toxic comment classification",
    "input_data": "The primary input data is a single text field, `comment_text`, which contains the content of an online comment. A key characteristic of this task is the cross-lingual setting: the training data is entirely in English",
    "output_data": "The output is a single probability value between 0.0 and 1.0. This value represents the likelihood that the given `comment_text` is \"toxic\", where 1.0 indicates a toxic comment and 0.0 indicates a non-toxic comment.",
    "task": "The objective is to build a model that can classify whether an online comment is toxic. Predict the toxicity of the comment in the test dataset and output the result in submission.csv which have the same format as sample_submission.csv, evaluate the model on the test_ground_truth.csv",
    "data file description": {
      "jigsaw-toxic-comment-train.csv": "These are the primary training files, containing a large number of comments in English, each with a `comment_text` and a `toxic` label (0 or 1).",
      "test.csv": "The test dataset, evaluate the model on this dataset.This file does not contain the `toxic` label.",
      "sample_submission.csv": "An example file showing the required submission format, which includes an `id` column and a `toxic` probability column.",
      "test_ground_truth.csv": "The ground truth of the test dataset, which includes an `id` column and a `toxic` label column."
    },
    "link to the dataset": [
      "first_5\\datasets\\toxic_cmt_classify\\jigsaw-toxic-comment-train.csv",
      "first_5\\datasets\\toxic_cmt_classify\\test.csv",
      "first_5\\datasets\\toxic_cmt_classify\\sample_submission.csv"
    ],
    "link to the ground truth": [
      "first_5\\ground_truths\\toxic_comment_classify\\test_ground_truth.csv"
    ]
  },
  {
    "id": "3",
    "name": "Domain classification",
    "input_data": "The input data for each sample consists of 1 text fields:`Title`: The title of the paper.",
    "output_data": "The output is a probability distribution across numbers of domains.",
    "task": "The objective is to build a model that can classify the domain of a paper based on its title.Predict the domain of the paper in the test dataset and output the result in submission.csv which have the same format as sample_submission.csv, evaluate the model on the test_ground_truth.csv",
    "data file description": "`train.csv`: Contains the training data. Each row represents a paper and includes its `Title` and `Domain`, `train.csv` is the training dataset, `test.csv` is the test dataset, `sample_submission.csv` is the sample submission file, `test_ground_truth.csv` is the ground truth of the test dataset.",
    "link to the dataset": [
      "first_5\\datasets\\query_domain_classification\\train.csv",
      "first_5\\datasets\\query_domain_classification\\test.csv",
      "first_5\\datasets\\query_domain_classification\\Submission_file01.csv"
    ],
    "link to the ground truth": [
      "first_5\\ground_truths\\query_domain_classification\\test_ground_truth.csv"
    ]
  },
  {
    "id": "4",
    "name": "Predict LLM",
    "input_data": "The input data for each sample consists of two text fields: `Question` (the original prompt or question that was given to a language model) and `Response` (the text output that was generated by one of the language models in response to the `Question`).",
    "output_data": "The output is a probability distribution across 7 possible classes. Each class corresponds to one of the 7 different LLM models that could have generated the `Response`. The final submission requires predicting the probability for each of the 7 models (target_0 to target_6).",
    "task": " For each given pair of `Question` and `Response`, identify which of the 7 LLM models generated the `Response`. This is a multi-class classification task where the output is a set of probabilities for each class.",
    "data file description": "`train.csv`: Contains the training data with three columns: `Question`, `Response`, and `target` (an integer from 0 to 6 indicating the correct model).",
    "link to the dataset": [
      "E:\\UET\\Lab\\AutoPipelineML\\PredictLLM\\train.csv"
    ],
    "link to the ground truth":[]
  },
  {
    "id": "5",
    "name": "Multilabel classification",
    "input_data": "The input data is multimodal, consisting of two parts for each sample: Image Data (A JPEG image file) and Text Data (Optional: A short text caption that summarizes the image).",
    "output_data": "The output is a set of one or more labels for each image. There are 18 possible labels in total, represented by integers ranging from 1 to 19 (with the number 12 missing).",
    "task": "For each given sample, predict all applicable labels. Since a single image can have multiple labels simultaneously, this is a multi-label classification task. The model should be trained on images and can optionally use the text captions as additional input.",
    "data file description": "- `train.csv`: The training set file. It contains three columns: `ImageID` (the filename of the image), `Labels` (a space-separated string of label numbers for that image), and `Caption` (the text caption).\n- `data/`: A directory containing all the image files in `.jpg` format.",
    "link to the dataset": [
      "E:\\UET\\Lab\\AutoPipelineML\\MultilabelClassify\\COMP5329S1A2Dataset\\data",
      "E:\\UET\\Lab\\AutoPipelineML\\MultilabelClassify\\COMP5329S1A2Dataset\\train.csv"
    ],
    "link to the ground truth": []
  },
  {
    "id": "6",
    "name": "Plant Traits 2024",
    "input_data": "The input data is multimodal, consisting of two main types for each sample: 1) Image Data: A crowd-sourced photograph of a plant (`.jpeg`). 2) Tabular Ancillary Data: A set of geographical and environmental features associated with the image's location. This includes climate data (WORLDCLIM), soil data (SOIL), and multi-temporal satellite data (MODIS, VOD).",
    "output_data": "The output consists of 6 continuous numerical values. Each value is a prediction for one of the 6 vital plant traits , representing properties like leaf area or plant height.",
    "task": "For each sample, predict the values for all 6 plant traits based on the plant image and its associated ancillary data. This is a multi-output regression task that requires a multi-modal model to handle both image and tabular inputs.",
    "data file description": "- `train.csv`: Contains the training data. For each `id`, it includes the target values for the 6 plant traits (columns named `X[*]_mean`) and all the ancillary tabular data (columns like `WORLDCLIM_BIO[*]`, `SOIL_[*]`, etc.).\n- `train_images/`: A directory containing the training images, with filenames corresponding to the `id` in `train.csv`.\n- `target_name_meta.tsv`: A helper file providing the full names and descriptions for each trait ID.",
    "link to the dataset": [
      "E:\\UET\\Lab\\AutoPipelineML\\PlantTraits\\train.csv",
      "E:\\UET\\Lab\\AutoPipelineML\\PlantTraits\\train_images",
      "E:\\UET\\Lab\\AutoPipelineML\\PlantTraits\\target_name_meta.tsv"
    ],
    "link to the ground truth": []
  }
]